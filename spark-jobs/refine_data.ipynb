{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2198fe0e",
   "metadata": {},
   "source": [
    "### Refining the data before curation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff354d9",
   "metadata": {},
   "source": [
    "#### Costumers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1a31c",
   "metadata": {},
   "source": [
    "O que é Particionamento no Spark?\n",
    "É uma técnica de organização de dados que:\n",
    "\n",
    "Divide fisicamente os arquivos por valores de colunas\n",
    "\n",
    "Cria subpastas automáticas no formato nome_coluna=valor\n",
    "\n",
    "Melhora performance em consultas filtradas por essas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246d60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Lendo dados de: c:\\Users\\pacie\\Desktop\\Projeto A\\data_lake\\parquet\\brazilian_ecommerce_v4\\olist_customers_dataset\n",
      "🔄 Transformando dados...\n",
      "💾 Salvando em: c:\\Users\\pacie\\Desktop\\Projeto A\\data_lake\\refined\\customers\n",
      "✅ Estrutura criada:\n",
      "📁 ...\\data_lake\\refined\\customers\n",
      "   └── customer_region=Centro-Oeste\n",
      "   └── customer_region=Nordeste\n",
      "   └── customer_region=Norte\n",
      "   └── customer_region=Outras\n",
      "   └── customer_region=Sudeste\n",
      "   └── customer_region=Sul\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Centro-Oeste\n",
      "   └── customer_state_clean=DF\n",
      "   └── customer_state_clean=GO\n",
      "   └── customer_state_clean=MS\n",
      "   └── customer_state_clean=MT\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Centro-Oeste\\customer_state_clean=DF\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Centro-Oeste\\customer_state_clean=GO\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Centro-Oeste\\customer_state_clean=MS\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Centro-Oeste\\customer_state_clean=MT\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\n",
      "   └── customer_state_clean=AL\n",
      "   └── customer_state_clean=BA\n",
      "   └── customer_state_clean=CE\n",
      "   └── customer_state_clean=MA\n",
      "   └── customer_state_clean=PB\n",
      "   └── customer_state_clean=PE\n",
      "   └── customer_state_clean=PI\n",
      "   └── customer_state_clean=RN\n",
      "   └── customer_state_clean=SE\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=AL\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=BA\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=CE\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=MA\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=PB\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=PE\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=PI\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=RN\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Nordeste\\customer_state_clean=SE\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Norte\n",
      "   └── customer_state_clean=AC\n",
      "   └── customer_state_clean=AM\n",
      "   └── customer_state_clean=AP\n",
      "   └── customer_state_clean=PA\n",
      "   └── customer_state_clean=RO\n",
      "   └── customer_state_clean=RR\n",
      "   └── customer_state_clean=TO\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Norte\\customer_state_clean=AC\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Norte\\customer_state_clean=AM\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Norte\\customer_state_clean=AP\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Norte\\customer_state_clean=PA\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Norte\\customer_state_clean=RO\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Norte\\customer_state_clean=RR\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Norte\\customer_state_clean=TO\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\n",
      "   └── customer_state_clean=AC\n",
      "   └── customer_state_clean=AL\n",
      "   └── customer_state_clean=AM\n",
      "   └── customer_state_clean=AP\n",
      "   └── customer_state_clean=BA\n",
      "   └── customer_state_clean=CE\n",
      "   └── customer_state_clean=DF\n",
      "   └── customer_state_clean=GO\n",
      "   └── customer_state_clean=MA\n",
      "   └── customer_state_clean=MS\n",
      "   └── customer_state_clean=MT\n",
      "   └── customer_state_clean=PA\n",
      "   └── customer_state_clean=PB\n",
      "   └── customer_state_clean=PE\n",
      "   └── customer_state_clean=PI\n",
      "   └── customer_state_clean=RN\n",
      "   └── customer_state_clean=RO\n",
      "   └── customer_state_clean=RR\n",
      "   └── customer_state_clean=SE\n",
      "   └── customer_state_clean=TO\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=AC\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=AL\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=AM\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=AP\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=BA\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=CE\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=DF\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=GO\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=MA\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=MS\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=MT\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=PA\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=PB\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=PE\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=PI\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=RN\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=RO\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=RR\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=SE\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Outras\\customer_state_clean=TO\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sudeste\n",
      "   └── customer_state_clean=ES\n",
      "   └── customer_state_clean=MG\n",
      "   └── customer_state_clean=RJ\n",
      "   └── customer_state_clean=SP\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sudeste\\customer_state_clean=ES\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sudeste\\customer_state_clean=MG\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sudeste\\customer_state_clean=RJ\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sudeste\\customer_state_clean=SP\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sul\n",
      "   └── customer_state_clean=PR\n",
      "   └── customer_state_clean=RS\n",
      "   └── customer_state_clean=SC\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sul\\customer_state_clean=PR\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sul\\customer_state_clean=RS\n",
      "📁 ...\\data_lake\\refined\\customers\\customer_region=Sul\\customer_state_clean=SC\n"
     ]
    }
   ],
   "source": [
    "# customer_refinement_fixed.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import os\n",
    "\n",
    "# 1. Configuração de caminhos ABSOLUTOS\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(os.getcwd()))  # Volta um nível para o projeto\n",
    "INPUT_PATH = os.path.join(BASE_DIR, \"data_lake\", \"parquet\", \"brazilian_ecommerce_v4\", \"olist_customers_dataset\")\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"data_lake\", \"refined\", \"customers\")  # Pasta definitiva\n",
    "\n",
    "# 2. Função de transformação\n",
    "def transform_customers(df):\n",
    "    # Limpeza\n",
    "    df_clean = (df\n",
    "        .withColumn(\"customer_city_clean\", lower(trim(col(\"customer_city\"))))\n",
    "        .withColumn(\"customer_state_clean\", upper(trim(col(\"customer_state\"))))\n",
    "        .dropDuplicates([\"customer_id\"])\n",
    "    )\n",
    "    \n",
    "    # Cria região (exemplo simplificado)\n",
    "    return df_clean.withColumn(\n",
    "        \"customer_region\",\n",
    "        when(col(\"customer_state_clean\").isin([\"SP\", \"RJ\", \"MG\", \"ES\"]), \"Sudeste\")\n",
    "        .when(col(\"customer_state_clean\").isin([\"RS\", \"SC\", \"PR\"]), \"Sul\")\n",
    "        .when(col(\"customer_state_clean\").isin([\"MT\", \"MS\", \"GO\", \"DF\"]), \"Centro-Oeste\")\n",
    "        .when(col(\"customer_state_clean\").isin([\"AM\", \"PA\", \"AC\", \"RO\", \"RR\", \"AP\", \"TO\"]), \"Norte\")\n",
    "        .when(col(\"customer_state_clean\").isin([\"BA\", \"SE\", \"AL\", \"PE\", \"PB\", \"RN\", \"CE\", \"PI\", \"MA\"]), \"Nordeste\")\n",
    "        .otherwise(\"Outros\")  # Apenas para casos extremos não mapeados\n",
    "    )\n",
    "\n",
    "# 3. Execução principal\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"CustomerRefinement\") \\\n",
    "        .config(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    try:\n",
    "        # Garante que a pasta de output existe\n",
    "        os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "        \n",
    "        print(\"📂 Lendo dados de:\", INPUT_PATH)\n",
    "        customers_df = spark.read.parquet(INPUT_PATH)\n",
    "        \n",
    "        print(\"🔄 Transformando dados...\")\n",
    "        customers_refined = transform_customers(customers_df)\n",
    "        \n",
    "        print(\"💾 Salvando em:\", OUTPUT_PATH)\n",
    "        (customers_refined.write\n",
    "            .mode(\"overwrite\")\n",
    "            .partitionBy(\"customer_region\", \"customer_state_clean\")  # Partição dupla\n",
    "            .parquet(OUTPUT_PATH))\n",
    "        \n",
    "        # Verificação\n",
    "        print(\"✅ Estrutura criada:\")\n",
    "        for root, dirs, files in os.walk(OUTPUT_PATH):\n",
    "            print(f\"📁 {root.replace(BASE_DIR, '...')}\")\n",
    "            for dir in dirs:\n",
    "                if \"=\" in dir:  # Mostra apenas pastas de partição\n",
    "                    print(f\"   └── {dir}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro: {str(e)}\")\n",
    "    finally:\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48202e16",
   "metadata": {},
   "source": [
    "### Geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0187ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📍 Lendo dados de geolocalização...\n",
      "🛠️ Processando dados...\n",
      "💾 Salvando em: c:\\Users\\pacie\\Desktop\\Projeto A\\data_lake\\refined\\geolocation\n",
      "✅ Dados salvos! Estrutura:\n",
      "Total de registros: 1000163\n",
      "\n",
      "Amostra dos dados transformados:\n",
      "+---------------------------+------------------+-------------------+----------------+-----------------+----------------------+-----------------------+--------+--------------------+\n",
      "|geolocation_zip_code_prefix|   geolocation_lat|    geolocation_lng|geolocation_city|geolocation_state|geolocation_city_clean|geolocation_state_clean|  region|           geo_point|\n",
      "+---------------------------+------------------+-------------------+----------------+-----------------+----------------------+-----------------------+--------+--------------------+\n",
      "|                      50760|-8.072588074383969| -34.91359211518264|          recife|               PE|                recife|                     PE|Nordeste|POINT(-34.9135921...|\n",
      "|                      50740|-8.042627210658422|-34.946004300305844|          recife|               PE|                recife|                     PE|Nordeste|POINT(-34.9460043...|\n",
      "|                      50751|-8.066622635581963|-34.917061201223355|          recife|               PE|                recife|                     PE|Nordeste|POINT(-34.9170612...|\n",
      "+---------------------------+------------------+-------------------+----------------+-----------------+----------------------+-----------------------+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Exemplo de estrutura gerada:\n",
      "📁 c:\\Users\\pacie\\Desktop\\Projeto A\\data_lake\\refined\\geolocation\\region=Sudeste\n",
      "   Estados: ['geolocation_state_clean=ES', 'geolocation_state_clean=MG', 'geolocation_state_clean=RJ', 'geolocation_state_clean=SP']\n",
      "📁 c:\\Users\\pacie\\Desktop\\Projeto A\\data_lake\\refined\\geolocation\\region=Nordeste\n",
      "   Estados: ['geolocation_state_clean=AL', 'geolocation_state_clean=BA', 'geolocation_state_clean=CE', 'geolocation_state_clean=MA', 'geolocation_state_clean=PB', 'geolocation_state_clean=PE', 'geolocation_state_clean=PI', 'geolocation_state_clean=RN', 'geolocation_state_clean=SE']\n",
      "📁 c:\\Users\\pacie\\Desktop\\Projeto A\\data_lake\\refined\\geolocation\\region=Sul\n",
      "   Estados: ['geolocation_state_clean=PR', 'geolocation_state_clean=RS', 'geolocation_state_clean=SC']\n"
     ]
    }
   ],
   "source": [
    "# geolocation_refinement.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import os\n",
    "\n",
    "# Configuração de caminhos\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(os.getcwd()))  # Volta um nível\n",
    "INPUT_PATH = os.path.join(BASE_DIR, \"data_lake\", \"parquet\", \"brazilian_ecommerce_v4\", \"olist_geolocation_dataset\")\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"data_lake\", \"refined\", \"geolocation\")\n",
    "\n",
    "def transform_geolocation_data(df):\n",
    "    \"\"\"Transforma os dados de geolocalização com:\n",
    "    - Limpeza de textos\n",
    "    - Categorização por região\n",
    "    - Controle de qualidade\n",
    "    \"\"\"\n",
    "    # Limpeza e padronização\n",
    "    df_clean = (df\n",
    "        .withColumn(\"geolocation_city_clean\", lower(trim(col(\"geolocation_city\"))))\n",
    "        .withColumn(\"geolocation_state_clean\", upper(trim(col(\"geolocation_state\"))))\n",
    "        .na.drop(subset=[\"geolocation_zip_code_prefix\"])  # Remove registros sem CEP\n",
    "    )\n",
    "    \n",
    "    # Cria região geográfica (mesma lógica dos clientes)\n",
    "    df_with_region = df_clean.withColumn(\n",
    "        \"region\",\n",
    "        when(col(\"geolocation_state_clean\").isin([\"SP\", \"RJ\", \"MG\", \"ES\"]), \"Sudeste\")\n",
    "        .when(col(\"geolocation_state_clean\").isin([\"RS\", \"SC\", \"PR\"]), \"Sul\")\n",
    "        .when(col(\"geolocation_state_clean\").isin([\"MT\", \"MS\", \"GO\", \"DF\"]), \"Centro-Oeste\")\n",
    "        .when(col(\"geolocation_state_clean\").isin([\"AM\", \"PA\", \"AC\", \"RO\", \"RR\", \"AP\", \"TO\"]), \"Norte\")\n",
    "        .otherwise(\"Nordeste\")\n",
    "    )\n",
    "    \n",
    "    # Cria ponto geográfico (lat+lng)\n",
    "    return df_with_region.withColumn(\n",
    "        \"geo_point\",\n",
    "        format_string(\"POINT(%s %s)\", col(\"geolocation_lng\"), col(\"geolocation_lat\"))\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"GeolocationRefinement\").getOrCreate()\n",
    "    \n",
    "    try:\n",
    "        # Leitura\n",
    "        print(\"📍 Lendo dados de geolocalização...\")\n",
    "        geo_df = spark.read.parquet(INPUT_PATH)\n",
    "        \n",
    "        # Transformação\n",
    "        print(\"🛠️ Processando dados...\")\n",
    "        geo_refined = transform_geolocation_data(geo_df)\n",
    "        \n",
    "        # Escrita com particionamento por região/estado\n",
    "        print(\"💾 Salvando em:\", OUTPUT_PATH)\n",
    "        (geo_refined.write\n",
    "            .mode(\"overwrite\")\n",
    "            .partitionBy(\"region\", \"geolocation_state_clean\")\n",
    "            .option(\"compression\", \"snappy\")\n",
    "            .parquet(OUTPUT_PATH))\n",
    "        \n",
    "        # Verificação\n",
    "        print(\"✅ Dados salvos! Estrutura:\")\n",
    "        print(f\"Total de registros: {geo_refined.count()}\")\n",
    "        print(\"\\nAmostra dos dados transformados:\")\n",
    "        geo_refined.show(3)\n",
    "        \n",
    "        print(\"\\nExemplo de estrutura gerada:\")\n",
    "        for region in [\"Sudeste\", \"Nordeste\", \"Sul\"]:\n",
    "            path = os.path.join(OUTPUT_PATH, f\"region={region}\")\n",
    "            if os.path.exists(path):\n",
    "                print(f\"📁 {path}\")\n",
    "                print(f\"   Estados: {os.listdir(path)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Falha no processamento: {str(e)}\")\n",
    "        if 'geo_df' in locals():\n",
    "            print(\"\\nEsquema original:\", geo_df.printSchema())\n",
    "    finally:\n",
    "        spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
